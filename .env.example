# =============================================================================
# Lyra — variables de entorno
# Copiar este archivo a .env y completar los valores
# =============================================================================

# --- Requerido ---
DATABASE_URL=postgresql://usuario:password@localhost:5432/agentes

# --- Búsqueda web (opcional) ---
TAVILY_API_KEY=tvly-...

# --- Modelos en la nube (opcionales) ---
OPENAI_API_KEY=sk-...
DEEPSEEK_API_KEY=sk-...

# --- Modelo por defecto ---
# Formato: provider/nombre  → openai/gpt-4o, deepseek/deepseek-chat
# Nombre bare              → qwen3:14b (se trata como Ollama)
MODEL_NAME=qwen3:14b

# --- Contexto ---
MAX_CONTEXT_TOKENS=9000

# --- MCP ---
MCP_SERVERS_FILE=mcp_servers.json

# --- Logging ---
# Opciones: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=WARNING

# --- LangSmith (tracing opcional) ---
LANGSMITH_TRACING=false
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=lsv2_...
LANGSMITH_PROJECT=lyra
